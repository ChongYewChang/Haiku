{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652bc262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "with open(\"alchemist.txt\") as infile:\n",
    "    doc = nlp(infile.read())\n",
    "\n",
    "# matcher to create token patterns\n",
    "# pattern is a dictionary for a token, lemmas are base forms buy -> bought\n",
    "from spacy.matcher import Matcher\n",
    "matcher2 = Matcher(nlp.vocab)\n",
    "matcher3 = Matcher(nlp.vocab)\n",
    "matcher4 = Matcher(nlp.vocab)\n",
    "pattern = [{'POS':  {\"IN\": [\"NOUN\", \"ADP\", \"ADJ\", \"ADV\"]} },\n",
    "           {'POS':  {\"IN\": [\"NOUN\", \"VERB\"]} }]\n",
    "matcher2.add(\"TwoWords\", [pattern])\n",
    "pattern = [{'POS':  {\"IN\": [\"NOUN\", \"ADP\", \"ADJ\", \"ADV\"]} },\n",
    "           {'IS_ASCII': True, 'IS_PUNCT': False, 'IS_SPACE': False},\n",
    "           {'POS':  {\"IN\": [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"]} }]\n",
    "matcher3.add(\"ThreeWords\", [pattern])\n",
    "pattern = [{'POS':  {\"IN\": [\"NOUN\", \"ADP\", \"ADJ\", \"ADV\"]} },{'IS_ASCII': True, 'IS_PUNCT': False, 'IS_SPACE': False},{'IS_ASCII': True, 'IS_PUNCT': False, 'IS_SPACE': False},\n",
    "{'POS':  {\"IN\": [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"]} }]\n",
    "matcher4.add(\"FourWords\", [pattern])\n",
    "matches2 = matcher2(doc)\n",
    "matches3 = matcher3(doc)\n",
    "matches4 = matcher4(doc)\n",
    "# can i cache anywhere for fast retrival?\n",
    "\n",
    "import syllapy\n",
    "import random\n",
    "g_5 = []\n",
    "g_7 = []\n",
    "# foreach of the matched patterns if range total syllables is 5,7 add to list\n",
    "for match_id, start, end in matches2 + matches3 + matches4:\n",
    "    span = doc[start:end]\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    total_syl_count = 0\n",
    "    for token in span:\n",
    "        total_syl_count += syllapy.count(token.text)\n",
    "    if total_syl_count == 5:\n",
    "        if span.text not in g_5:\n",
    "            g_5.append(span.text)\n",
    "    if total_syl_count == 7:\n",
    "        if span.text not in g_7:\n",
    "            g_7.append(span.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246aaf76",
   "metadata": {},
   "source": [
    "- how can we improve this existing code? Then switch to a new method?\n",
    "\n",
    "- Machine learning for generation?\n",
    "\n",
    "- How to generate patterns dynamically? Is there any need for patterns if the haiku can make sense? restricted spans by patterns\n",
    "\n",
    "- should be a better way for matchers instead of creating new objects?\n",
    "\n",
    "- rating haikus? flow, theme, comedy!\n",
    "- might be able to use generative learning here\n",
    "\n",
    "- how to haikuify something? shakespearify\n",
    "\n",
    "- how to check sentence makes sense, span can but put together not very much https://stackoverflow.com/questions/10252448/how-to-check-whether-a-sentence-is-correct-simple-grammar-check-in-python\n",
    "\n",
    "- time decorator, how long?\n",
    "\n",
    "- computational poetry\n",
    "https://wwwfr.uni.lu/universite/actualites/a_la_une/computational_poetry_how_machines_create_art\n",
    "\n",
    "- spacy vs nltk\n",
    "https://towardsdatascience.com/here-are-5-free-natural-language-processing-courses-from-top-universities-f108e2456dce\n",
    "\n",
    "\n",
    "- caching serverless rest apis, cache result in /tmp just use the models\n",
    "https://blog.thundra.io/caching-with-aws-serverless-applications\n",
    "https://docs.aws.amazon.com/whitepapers/latest/security-overview-aws-lambda/security-overview-aws-lambda.html\n",
    "https://docs.aws.amazon.com/lambda/latest/dg/runtimes-context.html - execution context\n",
    "https://github.com/zappa/Zappa\n",
    "\n",
    "- very slow on kubernetes, maybe it doesnt understand some made up words\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "use kubernetes\n",
    "for updates and rollbacks\n",
    "support for scaling\n",
    "\n",
    "\n",
    "some generation mix and match, useful to group themes together, dynamic programming?? likely not\n",
    "\n",
    "\n",
    "domain name suffix\n",
    "basic networking knowledge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "82652e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for no apparent\n",
      "objective has been achieved\n",
      "driver answered\n",
      "\n",
      "longer believed in things\n",
      "wind's curiosity\n",
      "silent for a few\n",
      "\n",
      "dunes surrounding\n",
      "in an Arabic dialect\n",
      "wise men understood\n",
      "\n",
      "why should I listen\n",
      "treasure and your destiny\n",
      "tribes was over\n",
      "\n",
      "generously gave\n",
      "crystal merchant for almost\n",
      "reasons for being\n",
      "\n",
      "stranger in a strange\n",
      "also kept the alchemist\n",
      "old man's blessing\n",
      "\n",
      "faithful companions\n",
      "again covered by water\n",
      "just as your father\n",
      "\n",
      "same destination\n",
      "quality most essential\n",
      "of a chemical\n",
      "\n",
      "more delicious when\n",
      "adventurer as the ones\n",
      "sycamore was still\n",
      "\n",
      "crystal and crossed\n",
      "shelf brought many customers\n",
      "from his destiny\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    print(f\"{random.choice(g_5)}\\n{random.choice(g_7)}\\n{random.choice(g_5)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
